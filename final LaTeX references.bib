@article{hannun2014deepspeech,
  title={Deep Speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and Ng, Andrew Y.},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014}
}

@article{chan2016las,
  title={Listen, Attend and Spell},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc V. and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1508.01211},
  year={2016}
}

@inproceedings{radford2023whisper,
  title={Robust Speech Recognition via Large-Scale Weak Supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  editor={Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume={202},
  series={Proceedings of Machine Learning Research},
  month={July},
  publisher={PMLR}
}

@inproceedings{ko2015audioaugment,
  title={Audio Augmentation for Speech Recognition},
  author={Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Proceedings of Interspeech},
  pages={3586--3589},
  year={2015}
}

@inproceedings{park2019specaugment,
  title={SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
  author={Park, Daniel S. and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D. and Le, Quoc V.},
  booktitle={Proceedings of Interspeech},
  year={2019}
}

@article{alharbi2021asrreview,
  title={Automatic Speech Recognition: Systematic Literature Review},
  author={Alharbi, S. and Alrazgan, M. and Alrashed, A. and AlNomasi, T. and Almojel, R. and AlHarbi, R. and AlShehri, F. and Almojil, M.},
  journal={IEEE Access},
  volume={9},
  pages={133517--133541},
  year={2021},
  doi={10.1109/ACCESS.2021.3112535}
}

@article{deepa2022speechhealthcare,
  title={Speech Technology in Healthcare},
  author={Deepa, P.},
  journal={Elsevier Health Sciences},
  year={2022},
  url={https://www.sciencedirect.com/science/article/pii/S2665917422001994}
}


@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423/",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186"
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{10.1093/bioinformatics/btz682,
    author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
    title = {BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
    journal = {Bioinformatics},
    volume = {36},
    number = {4},
    pages = {1234-1240},
    year = {2019},
    month = {09},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btz682},
    url = {https://doi.org/10.1093/bioinformatics/btz682},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/4/1234/48983216/bioinformatics_36_4_1234.pdf},
}

@misc{1881146593179904768,
author="Garofolo, John S. and Lamel, Lori F. and Fisher, William M. and Pallett, David S. and Dahlgren, Nancy L. and Zue, Victor and Fiscus, Jonathan G.",
title="TIMIT Acoustic-Phonetic Continuous Speech Corpus",
publisher="Linguistic Data Consortium",
year="1993",
month="01",
DOI="10.35111/17gk-bn40",
URL="https://cir.nii.ac.jp/crid/1881146593179904768"
}

@ARTICLE{7737032,
  author={Zinchenko, Kateryna and Wu, Chien-Yu and Song, Kai-Tai},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Study on Speech Recognition Control for a Surgical Robot}, 
  year={2017},
  volume={13},
  number={2},
  pages={607-615},
  keywords={Speech recognition;Endoscopes;Speech;Cameras;Service robots;Robot vision systems;Automated system;human–robot interface;motion control;robotic surgery;speech recognition control},
  doi={10.1109/TII.2016.2625818}}

@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={5998--6008},
  year={2017}
}

@InProceedings{pmlr-v48-amodei16,
  title = 	 {Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin},
  author = 	 {Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and Chen, Jie and Chen, Jingdong and Chen, Zhijie and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and Ding, Ke and Du, Niandong and Elsen, Erich and Engel, Jesse and Fang, Weiwei and Fan, Linxi and Fougner, Christopher and Gao, Liang and Gong, Caixia and Hannun, Awni and Han, Tony and Johannes, Lappi and Jiang, Bing and Ju, Cai and Jun, Billy and LeGresley, Patrick and Lin, Libby and Liu, Junjie and Liu, Yang and Li, Weigao and Li, Xiangang and Ma, Dongpeng and Narang, Sharan and Ng, Andrew and Ozair, Sherjil and Peng, Yiping and Prenger, Ryan and Qian, Sheng and Quan, Zongfeng and Raiman, Jonathan and Rao, Vinay and Satheesh, Sanjeev and Seetapun, David and Sengupta, Shubho and Srinet, Kavya and Sriram, Anuroop and Tang, Haiyuan and Tang, Liliang and Wang, Chong and Wang, Jidong and Wang, Kaifu and Wang, Yi and Wang, Zhijian and Wang, Zhiqian and Wu, Shuang and Wei, Likai and Xiao, Bo and Xie, Wen and Xie, Yan and Yogatama, Dani and Yuan, Bin and Zhan, Jun and Zhu, Zhenyao},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {173--182},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/amodei16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/amodei16.html}
}

@inproceedings{Watanabe2018ESPnetES,
  title={ESPnet: End-to-End Speech Processing Toolkit},
  author={Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and Yuya Unno and Nelson Yalta and Jahn Heymann and Matthew Wiesner and Nanxin Chen and Adithya Renduchintala and Tsubasa Ochiai},
  booktitle={Interspeech},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:4556070}
}

@article{Balam2020ImprovingNR,
  title={Improving Noise Robustness of an End-to-End Neural Model for Automatic Speech Recognition},
  author={Jagadeesh Balam and Jocelyn Huang and Vitaly Lavrukhin and Slyne Deng and Somshubra Majumdar and Boris Ginsburg},
  journal={arXiv: Audio and Speech Processing},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:225066868}
}


@Article{app132011586,
AUTHOR = {Sasanelli, Francesca and Le, Khang Duy Ricky and Tay, Samuel Boon Ping and Tran, Phong and Verjans, Johan W.},
TITLE = {Applications of Natural Language Processing Tools in Orthopaedic Surgery: A Scoping Review},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {20},
ARTICLE-NUMBER = {11586},
URL = {https://www.mdpi.com/2076-3417/13/20/11586},
ISSN = {2076-3417},
DOI = {10.3390/app132011586}
}


@article{malik2021asrsurvey,
  title={Automatic Speech Recognition: A Survey},
  author={Malik, Mishaim and Malik, Muhammad Kamran and Mehmood, Khawar and Makhdoom, Imran},
  journal={Multimedia Tools and Applications},
  volume={80},
  number={6},
  pages={9411--9457},
  year={2021},
  publisher={Springer},
  doi={10.1007/s11042-020-10073-7},
  url={https://doi.org/10.1007/s11042-020-10073-7}
}

@article{Liu2019RoBERTaAR,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692},
  url={https://api.semanticscholar.org/CorpusID:198953378}
}

@inproceedings{Peng2019TransferLI,
  title={Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets},
  author={Yifan Peng and Shankai Yan and Zhiyong Lu},
  booktitle={BioNLP@ACL},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:189762009}
}

@INPROCEEDINGS{7472669,
  author={Trigeorgis, George and Ringeval, Fabien and Brueckner, Raymond and Marchi, Erik and Nicolaou, Mihalis A. and Schuller, Björn and Zafeiriou, Stefanos},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Adieu features? End-to-end speech emotion recognition using a deep convolutional recurrent network}, 
  year={2016},
  volume={},
  number={},
  pages={5200-5204},
  keywords={Speech;Convolution;Feature extraction;Speech recognition;Acoustics;Neural networks;Emotion recognition;end-to-end learning;raw waveform;emotion recognition;deep learning;CNN;LSTM},
  doi={10.1109/ICASSP.2016.7472669}}


@inproceedings{10.1145/1873951.1874246,
author = {Eyben, Florian and W\"{o}llmer, Martin and Schuller, Bj\"{o}rn},
title = {Opensmile: the munich versatile and fast open-source audio feature extractor},
year = {2010},
isbn = {9781605589336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1873951.1874246},
doi = {10.1145/1873951.1874246},
abstract = {We introduce the openSMILE feature extraction toolkit, which unites feature extraction algorithms from the speech processing and the Music Information Retrieval communities. Audio low-level descriptors such as CHROMA and CENS features, loudness, Mel-frequency cepstral coefficients, perceptual linear predictive cepstral coefficients, linear predictive coefficients, line spectral frequencies, fundamental frequency, and formant frequencies are supported. Delta regression and various statistical functionals can be applied to the low-level descriptors. openSMILE is implemented in C++ with no third-party dependencies for the core functionality. It is fast, runs on Unix and Windows platforms, and has a modular, component based architecture which makes extensions via plug-ins easy. It supports on-line incremental processing for all implemented features as well as off-line and batch processing. Numeric compatibility with future versions is ensured by means of unit tests. openSMILE can be downloaded from http://opensmile.sourceforge.net/.},
booktitle = {Proceedings of the 18th ACM International Conference on Multimedia},
pages = {1459–1462},
numpages = {4},
keywords = {audio feature extraction, emotion, music, signal processing, speech, statistical functionals},
location = {Firenze, Italy},
series = {MM '10}
}

@INPROCEEDINGS{10447520,
  author={Ferraz, Thomas Palmeira and Zanon Boito, Marcely and Brun, Caroline and Nikoulina, Vassilina},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Multilingual Distilwhisper: Efficient Distillation of Multi-Task Speech Models Via Language-Specific Experts}, 
  year={2024},
  volume={},
  number={},
  pages={10716-10720},
  keywords={Adaptation models;Costs;Training data;Signal processing;Logic gates;Multitasking;Robustness;knowledge distillation;multitask speech processing;automatic speech recognition;multilingual speech processing;language experts},
  doi={10.1109/ICASSP48485.2024.10447520}}

@article{Wang2023ClinicalGPTLL,
  title={ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation},
  author={Guangyu Wang and Guoxing Yang and Zongxin Du and Longjun Fan and Xiaohu Li},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.09968},
  url={https://api.semanticscholar.org/CorpusID:259187929}
}





